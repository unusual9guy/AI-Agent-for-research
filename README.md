# ğŸ¤– AI Research Agent

An intelligent AI research assistant built with LangChain that can conduct comprehensive research on any topic and generate professional academic-style reports. The agent uses multiple search tools and LLM providers to deliver well-structured, cited research outputs.

## âœ¨ Features

- ğŸ” **Multi-Source Research**: Integrates Wikipedia, Tavily web search, and custom tools
- ğŸ§  **Multiple LLM Support**: Works with OpenAI, Groq, Google Gemini, and Ollama
- ğŸ“„ **Structured Output**: Generates properly formatted academic reports with citations
- ğŸ’¾ **Automatic File Saving**: Saves research outputs to organized files
- ğŸ–¥ï¸ **Interactive CLI**: User-friendly command-line interface with colored output
- ğŸ“ **Professional Formatting**: Produces research reports with abstracts, introductions, detailed analysis, and conclusions

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Framework** | ğŸ¦œ [LangChain](https://langchain.com/) | Agent orchestration and tool management |
| **LLM Providers** | ğŸ¤– OpenAI GPT-4, Groq Llama, Google Gemini, Ollama | Natural language processing and generation |
| **Search Tools** | ğŸŒ Tavily API, Wikipedia API, DuckDuckGo | Information retrieval and web searching |
| **Data Validation** | ğŸ“‹ Pydantic | Output structure validation and parsing |
| **Environment** | ğŸ Python 3.8+ | Core programming language |
| **CLI Interface** | ğŸ¨ Termcolor | Enhanced terminal user experience |
| **Configuration** | ğŸ” python-dotenv | Environment variable management |

## ğŸ“‹ Prerequisites

- Python 3.8+ ğŸ
- API keys for your chosen LLM provider(s) ğŸ”‘
- Tavily API key for web search functionality ğŸŒ

## ğŸš€ Installation

### 1. ğŸ—ï¸ Create Virtual Environment

```bash
# Create virtual environment
python -m venv ai_research_env

# Activate virtual environment
# On Windows:
ai_research_env\Scripts\activate
# On macOS/Linux:
source ai_research_env/bin/activate
```

### 2. ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. ğŸ” Set Up Environment Variables

Create a `.env` file in the project root and add your API keys:

```env
OPENAI_API_KEY=your_openai_api_key_here
GROQ_API_KEY=your_groq_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
```

**Note**: You only need to provide API keys for the LLM providers you plan to use. ğŸ’¡

## ğŸ“ Project Structure

```
ai-research-agent/
â”œâ”€â”€ main.py              # Main application entry point
â”œâ”€â”€ tools.py             # Research tools configuration
â”œâ”€â”€ cl_ui.py             # Command-line user interface
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env                 # Environment variables
â”œâ”€â”€ outputs/             # Generated research reports
â””â”€â”€ README.md           # This file
```

## ğŸš€ Usage

### Basic Usage ğŸ’»

Run the research agent with your preferred LLM:

```bash
# Using OpenAI GPT-4
python main.py openai

# Using Groq Llama
python main.py groq

# Using Google Gemini
python main.py google_genai

# Using Ollama (local)
python main.py ollama
```

### Example Session ğŸ¯

```bash
$ python main.py openai
============================================================
ğŸ”¬  AI RESEARCH ASSISTANT
============================================================
Enter your research topic below. The assistant will generate a detailed, academic-style report.

ğŸ“ Enter your research topic: Climate change impacts on marine ecosystems

â³ Researching and drafting your report... please wait.
```

## ğŸ¤– Supported LLM Providers

| Provider | Model | Command |
|----------|-------|---------|
| ğŸ¤– OpenAI | GPT-4o-mini | `python main.py openai` |
| âš¡ Groq | Llama3-70b-8192 | `python main.py groq` |
| ğŸŸ¢ Google | Gemini-2.5-flash | `python main.py google_genai` |
| ğŸ¦™ Ollama | Llama3.2:3b | `python main.py ollama` |

## ğŸ”§ Research Tools

The agent uses the following tools for comprehensive research:

- ğŸŒ **Tavily Search**: Real-time web search with structured results
- ğŸ“š **Wikipedia Lookup**: Authoritative encyclopedic information
- ğŸ’¾ **File Saver**: Automatically saves reports to the `outputs/` directory

## ğŸ“Š Output Format

The agent generates structured research reports containing:

- ğŸ¯ **Topic**: Research subject
- ğŸ“ **Abstract**: Executive summary
- ğŸ“– **Introduction**: Context and background
- ğŸ” **Detailed Research**: Comprehensive analysis (1000-1500 words)
- âœ… **Conclusion**: Key findings and implications
- ğŸ“š **Citations**: Properly formatted references
- ğŸŒ **Sources**: List of consulted materials
- ğŸ·ï¸ **Keywords**: Relevant terms and concepts
- ğŸ“Š **Confidence Score**: Quality assessment
- ğŸ“„ **Page Count**: Estimated document length

## âš™ï¸ Configuration

### ğŸ”§ Customizing Tools

Edit `tools.py` to modify search parameters:

```python
# Adjust Wikipedia results
api_wrapper = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=2000)

# Modify Tavily search depth
tavily = TavilySearchResults(k=10)
```

### ğŸ¨ Modifying Output Format

Update the `ResearchResponse` class in `main.py` to customize the report structure:

```python
class ResearchResponse(BaseModel):
    topic: str
    abstract: str
    # Add or modify fields as needed
    custom_field: str
```

## ğŸ› ï¸ Troubleshooting

### âš ï¸ Common Issues

1. **ğŸ”‘ API Key Errors**
   - Ensure all required API keys are set in `.env`
   - Verify API key validity and quotas

2. **ğŸ“¦ Import Errors**
   - Activate virtual environment before running
   - Install all dependencies: `pip install -r requirements.txt`

3. **â±ï¸ Rate Limiting**
   - Some providers have rate limits; wait between requests
   - Consider switching to a different LLM provider

4. **ğŸ”§ Parsing Errors**
   - The agent expects structured JSON output
   - Check LLM provider compatibility and model versions

### ğŸ†˜ Getting Help

If you encounter issues:

1. Check the verbose output by ensuring `verbose=True` in `AgentExecutor`
2. Verify your API keys and internet connection
3. Ensure all dependencies are properly installed

## Contributing

Feel free to submit issues, fork the repository, and create pull requests for any improvements.

## License

This project is open source and available under the MIT License.

## Acknowledgments

- Built with [LangChain](https://langchain.com/)
- Powered by various LLM providers
- Uses Tavily for web search capabilities